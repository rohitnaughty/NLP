{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40c0dbc7-1cd2-4305-862e-78359eaf47fc",
   "metadata": {},
   "source": [
    "1 Can you think of a few applications for a sequence-to-sequence RNN? What about a sequence-to-vector RNN? And a vector-to-sequence RNN?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27092dfd-bc13-41f1-8e9c-1cc44bf49d74",
   "metadata": {},
   "source": [
    "Application:- chatbot, question-answer, text summarization, machine translation, etc.It is like a encoder-decoder model\n",
    "which first we have a temporal information and we condense it down to a vector which we can call it a \"concept vector\".\n",
    "The RNN model takes a single vector as input and produced a sequence as output called vector  to sequence rnn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3cd202-29f9-42d3-940d-b73f2131c437",
   "metadata": {},
   "source": [
    "2. Why do people use encoderâ€“decoder RNNs rather than plain sequence-to-sequence RNNs for automatic translation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b0e2f2-3ff6-4b84-afa4-3873a3bd1c1e",
   "metadata": {},
   "source": [
    "The last words of a sentence can affect the first words of the translation, so you need to wait until you have heard the \n",
    "whole sentence before translating it. Thats why use encoder-decoder instead of sequence to sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7e7b54-0b9a-435c-a162-84bd8be42664",
   "metadata": {},
   "source": [
    "3. How could you combine a convolutional neural network with an RNN to classify videos?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f695d9-5ded-42fc-8ea0-ecb31ee90107",
   "metadata": {},
   "source": [
    "Each video is converted into sequential images and passed onto the CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625a026c-729a-4147-9e9d-659c8c1a681d",
   "metadata": {},
   "source": [
    "4. What are the advantages of building an RNN using dynamic_rnn() rather than static_rnn()?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a017d2c-c14b-4cde-91b8-38a6ff2cbd61",
   "metadata": {},
   "source": [
    "If uses a tf.While loop to dynamically construct the graph when it is executed.That means graph creation is faster and \n",
    "you can feed batches of variable size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e920aea-bf09-43a6-be71-be9b98955e59",
   "metadata": {},
   "source": [
    "5. How can you deal with variable-length input sequences?What about variable-length output sequences?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f542b5d-7658-45cf-85d9-0b94ef3b5c45",
   "metadata": {},
   "source": [
    "The first and simplest way of handling variable length input is to set a special mask value in the dataset, and pad out \n",
    "the length of each input to the standard length with this mask value set for all additional entries created. Then, create\n",
    "a Masking layer in the model, placed ahead of all downstream layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f7340f-03ff-4c41-98e7-95687a9e98cc",
   "metadata": {},
   "source": [
    "6. What is a common way to distribute training and execution of a deep RNN across multiple GPUs?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6493d688-7ecc-483b-8b40-97f75ccd8559",
   "metadata": {},
   "source": [
    "MirroredStrategy supports synchronous distributed training ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bc3a95-3761-4eda-9f06-20e875b02960",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
